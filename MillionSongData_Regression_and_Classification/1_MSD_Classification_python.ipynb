{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(appName='1_MSD_Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and check the data \n",
    "#import os.path\n",
    "#baseDir = os.path.join('data')\n",
    "#inputPath = os.path.join('YearPredictionMSD.csv')\n",
    "#fileName = os.path.join(baseDir, inputPath)\n",
    "numPartitions = 2\n",
    "path = 'hdfs://localhost:9000//user/praneeth/data/YearPredictionMSD.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = sc.textFile(path, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample data\n",
    "numPoints = rawData.count()\n",
    "print numPoints\n",
    "samplePoints = rawData.take(5)\n",
    "print samplePoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors, Matrices\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsePoint(line):\n",
    "    values = line.split(',')\n",
    "    return LabeledPoint(values[0], Vectors.dense(values[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsedSamplePoints = rawData.map(parsePoint).cache()\n",
    "#print parsedSamplePoints.take(2)\n",
    "#firstPointFeatures = parsedSamplePoints.take(1)[0].features\n",
    "#firstPointLabel = parsedSamplePoints.take(1)[0].label\n",
    "#print firstPointFeatures, firstPointLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedSamplePoints.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics,MultivariateStatisticalSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd = parsedSamplePoints.map(lambda a:a.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeld = parsedSamplePoints.map(lambda a:a.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2001.0, 2001.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeld.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = Statistics.colStats(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515345\n"
     ]
    }
   ],
   "source": [
    "print stats.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.33871256e+01   1.28955420e+00   8.65834709e+00   1.16412447e+00\n",
      "  -6.55360070e+00  -9.52197520e+00  -2.39108942e+00  -1.79323551e+00\n",
      "   3.72787581e+00   1.88238491e+00  -1.46527016e-01   2.54606336e+00\n",
      "   3.37140056e+01   2.43935938e+03   1.96773420e+03   1.51485990e+03\n",
      "   9.10981344e+02   8.79146721e+02   6.03737434e+02   5.17579339e+02\n",
      "   3.93962215e+02   3.25733170e+02   2.88885085e+02   2.91973238e+02\n",
      "   4.30319687e+01   4.33148725e+01  -4.64490057e+01  -2.76727830e+01\n",
      "   1.49584906e+01   4.45148595e+01   5.13178640e+00   2.40343086e+01\n",
      "   9.49881627e+00  -4.17885579e+00   4.99474661e-01   7.26522672e+01\n",
      "  -5.14412560e+01   1.17921056e+02  -1.89880885e+02   2.30960821e+01\n",
      "  -1.28300492e+00   1.81479733e+01  -5.19590221e+01   3.23268575e+00\n",
      "  -1.48832067e+00   6.33408380e+00   7.87024269e+01   1.42696868e+02\n",
      "  -8.65164764e+01   2.52407528e+01   6.37851064e+00   2.82940822e+01\n",
      "   1.27722407e+01   1.70047434e+00  -1.02051553e+01   6.41012625e+01\n",
      "   1.04822085e+02  -2.64808137e-02   3.86780403e+01  -2.79899851e+01\n",
      "   3.30173865e+00   3.07126834e-01  -4.78827587e-01  -1.38223224e+02\n",
      "  -6.96065128e-01   2.42582475e-01   3.15175098e+00   2.76427449e+01\n",
      "   3.18222436e+01  -8.35950125e-01  -8.93156350e+00   4.84925296e+00\n",
      "  -2.73476460e+01  -1.19387924e+01  -2.15721373e+01  -5.57619613e+00\n",
      "  -2.33043237e+01   3.11130528e+01  -1.04974794e+02   2.69623932e+01\n",
      "   1.57554060e+01  -7.34614998e+01   4.15424216e+01   3.79341187e+01\n",
      "   3.15751272e-01   1.76692132e+01  -2.63153360e+01   4.45864111e+00\n",
      "   2.00351364e+01   1.32910544e+00]\n"
     ]
    }
   ],
   "source": [
    "print stats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 515345.  515345.  515345.  515345.  515345.  515345.  515345.  515345.\n",
      "  515345.  515345.  515343.  515345.  515345.  515345.  515345.  515345.\n",
      "  515345.  515345.  515345.  515345.  515345.  515345.  515345.  515345.\n",
      "  515345.  515345.  515345.  515345.  515345.  515345.  515345.  515345.\n",
      "  515345.  515345.  515345.  515345.  515345.  515345.  515345.  515345.\n",
      "  515345.  515345.  515345.  515345.  515345.  515345.  515345.  515345.\n",
      "  515345.  515345.  515345.  515345.  515345.  515345.  515345.  515345.\n",
      "  515345.  515345.  515345.  515345.  515345.  515345.  515344.  515345.\n",
      "  515345.  515345.  515345.  515345.  515345.  515345.  515345.  515345.\n",
      "  515345.  515344.  515345.  515345.  515345.  515345.  515345.  515345.\n",
      "  515345.  515345.  515345.  515345.  515345.  515345.  515345.  515345.\n",
      "  515345.  515345.]\n"
     ]
    }
   ],
   "source": [
    "print stats.numNonzeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.68152638e+01   2.66053259e+03   1.24387308e+03   2.66433469e+02\n",
      "   5.22615510e+02   1.65321773e+02   2.12339488e+02   6.34225482e+01\n",
      "   1.11996937e+02   4.26439263e+01   1.91043134e+01   6.92255624e+01\n",
      "   4.95491232e+02   3.06028731e+06   1.59134388e+06   1.19427969e+06\n",
      "   2.26298295e+05   3.32774375e+05   1.00805798e+05   9.57065390e+04\n",
      "   4.58017789e+04   2.74562854e+04   3.49543141e+04   2.35547748e+04\n",
      "   1.47451230e+04   5.12311157e+05   2.96894068e+05   4.76847915e+04\n",
      "   2.66393937e+04   1.81947273e+04   9.81845540e+03   5.15666667e+03\n",
      "   5.53709808e+03   2.86407320e+03   1.80543373e+03   1.16451354e+04\n",
      "   1.72257455e+05   2.05570862e+05   6.79360087e+04   4.23287785e+04\n",
      "   1.43599185e+04   1.43630035e+04   5.42026025e+03   1.47255448e+03\n",
      "   1.72600967e+03   3.02218405e+03   2.21461908e+05   6.88380495e+04\n",
      "   4.39041429e+04   1.49215056e+04   8.75266382e+03   5.63239395e+03\n",
      "   4.89745921e+03   6.93533519e+03   3.34160201e+03   7.49813292e+04\n",
      "   9.68051738e+04   7.11683813e+04   2.85853963e+04   2.07599209e+04\n",
      "   3.53397005e+03   2.41881261e+03   1.41943756e+03   9.49794675e+04\n",
      "   4.93721819e+04   1.64201058e+04   9.98419615e+03   1.36179976e+04\n",
      "   1.13124363e+04   1.35418061e+03   6.33059587e+04   5.24686767e+04\n",
      "   2.68247465e+04   4.00548367e+03   4.18499605e+03   6.94753365e+02\n",
      "   7.19263654e+04   2.07810110e+04   4.04563028e+04   1.53383001e+04\n",
      "   1.03038657e+03   3.08419943e+04   1.49398793e+04   9.03462237e+03\n",
      "   2.61202618e+02   1.30937454e+04   3.02681135e+04   1.78130575e+02\n",
      "   3.44318629e+04   4.87905206e+02]\n"
     ]
    }
   ],
   "source": [
    "print stats.variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import VectorTransformer\n",
    "from pyspark.mllib.feature import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nor = Normalizer(1)\n",
    "newrdd=nor.transform(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DenseVector([0.0069, 0.003, 0.0101, 0.0012, -0.0024, -0.0018, -0.0035, -0.0017, 0.0011, -0.0003, 0.0005, -0.0003, 0.0014, 0.0846, 0.1316, 0.0966, 0.0566, 0.0531, 0.0452, 0.0329, 0.0348, 0.0259, 0.0139, 0.0248, -0.0012, -0.044, 0.0133, 0.0067, -0.0132, -0.0025, 0.0003, 0.0048, 0.0016, 0.0002, 0.0011, -0.0001, -0.0185, -0.0115, -0.0052, 0.0101, -0.0052, -0.0004, -0.0034, -0.0018, 0.0022, -0.0026, 0.0114, 0.0333, -0.0014, 0.0044, -0.0035, -0.0005, 0.0018, 0.0057, -0.001, -0.0029, 0.0146, 0.0089, 0.0036, -0.0062, -0.0011, 0.0011, -0.0015, -0.0132, -0.0114, -0.0049, 0.0006, 0.0098, 0.0039, 0.0008, -0.0051, -0.0057, -0.0012, 0.001, -0.0012, -0.0008, -0.0017, 0.002, -0.0075, 0.0056, 0.0018, -0.0075, 0.0082, 0.0021, 0.0002, -0.0032, 0.0095, -0.0003, -0.0038, 0.0003]),\n",
       " DenseVector([0.0044, 0.0017, 0.0064, 0.0012, -0.0009, -0.0023, 0.0008, -0.0001, 0.0017, 0.0004, 0.0002, 0.0, 0.004, 0.1875, 0.0552, 0.0417, 0.0708, 0.0379, 0.068, 0.0334, 0.029, 0.0249, 0.0129, 0.0289, 0.0018, -0.0059, 0.0148, 0.0123, -0.0088, -0.0079, 0.0016, 0.0042, 0.003, -0.003, 0.0041, 0.0024, -0.0276, -0.0038, -0.0127, 0.0184, -0.003, 0.0178, -0.0015, -0.0001, -0.0023, -0.0011, -0.0115, 0.0111, 0.0125, 0.0038, 0.0026, 0.0001, 0.0065, -0.004, -0.0039, 0.0118, 0.0073, -0.0079, -0.0042, -0.006, -0.004, -0.0018, 0.0011, -0.0372, 0.0039, 0.0011, -0.0081, 0.0039, 0.0042, -0.0028, 0.0042, 0.0119, 0.0013, -0.0004, 0.0016, -0.0017, -0.008, 0.0013, -0.0021, -0.0054, 0.0005, -0.0018, 0.003, 0.0039, -0.0009, -0.0029, 0.0064, 0.0011, 0.0053, 0.0025])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newrdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DenseVector([0.0069, 0.003, 0.0101, 0.0012, -0.0024, -0.0018, -0.0035, -0.0017, 0.0011, -0.0003, 0.0005, -0.0003, 0.0014, 0.0846, 0.1316, 0.0966, 0.0566, 0.0531, 0.0452, 0.0329, 0.0348, 0.0259, 0.0139, 0.0248, -0.0012, -0.044, 0.0133, 0.0067, -0.0132, -0.0025, 0.0003, 0.0048, 0.0016, 0.0002, 0.0011, -0.0001, -0.0185, -0.0115, -0.0052, 0.0101, -0.0052, -0.0004, -0.0034, -0.0018, 0.0022, -0.0026, 0.0114, 0.0333, -0.0014, 0.0044, -0.0035, -0.0005, 0.0018, 0.0057, -0.001, -0.0029, 0.0146, 0.0089, 0.0036, -0.0062, -0.0011, 0.0011, -0.0015, -0.0132, -0.0114, -0.0049, 0.0006, 0.0098, 0.0039, 0.0008, -0.0051, -0.0057, -0.0012, 0.001, -0.0012, -0.0008, -0.0017, 0.002, -0.0075, 0.0056, 0.0018, -0.0075, 0.0082, 0.0021, 0.0002, -0.0032, 0.0095, -0.0003, -0.0038, 0.0003]),\n",
       " DenseVector([0.0044, 0.0017, 0.0064, 0.0012, -0.0009, -0.0023, 0.0008, -0.0001, 0.0017, 0.0004, 0.0002, 0.0, 0.004, 0.1875, 0.0552, 0.0417, 0.0708, 0.0379, 0.068, 0.0334, 0.029, 0.0249, 0.0129, 0.0289, 0.0018, -0.0059, 0.0148, 0.0123, -0.0088, -0.0079, 0.0016, 0.0042, 0.003, -0.003, 0.0041, 0.0024, -0.0276, -0.0038, -0.0127, 0.0184, -0.003, 0.0178, -0.0015, -0.0001, -0.0023, -0.0011, -0.0115, 0.0111, 0.0125, 0.0038, 0.0026, 0.0001, 0.0065, -0.004, -0.0039, 0.0118, 0.0073, -0.0079, -0.0042, -0.006, -0.004, -0.0018, 0.0011, -0.0372, 0.0039, 0.0011, -0.0081, 0.0039, 0.0042, -0.0028, 0.0042, 0.0119, 0.0013, -0.0004, 0.0016, -0.0017, -0.008, 0.0013, -0.0021, -0.0054, 0.0005, -0.0018, 0.003, 0.0039, -0.0009, -0.0029, 0.0064, 0.0011, 0.0053, 0.0025])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nor1 = Normalizer(p=2)\n",
    "newrdd1=nor.transform(rdd)\n",
    "newrdd1.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DenseVector([0.0069, 0.003, 0.0101, 0.0012, -0.0024, -0.0018, -0.0035, -0.0017, 0.0011, -0.0003, 0.0005, -0.0003, 0.0014, 0.0846, 0.1316, 0.0966, 0.0566, 0.0531, 0.0452, 0.0329, 0.0348, 0.0259, 0.0139, 0.0248, -0.0012, -0.044, 0.0133, 0.0067, -0.0132, -0.0025, 0.0003, 0.0048, 0.0016, 0.0002, 0.0011, -0.0001, -0.0185, -0.0115, -0.0052, 0.0101, -0.0052, -0.0004, -0.0034, -0.0018, 0.0022, -0.0026, 0.0114, 0.0333, -0.0014, 0.0044, -0.0035, -0.0005, 0.0018, 0.0057, -0.001, -0.0029, 0.0146, 0.0089, 0.0036, -0.0062, -0.0011, 0.0011, -0.0015, -0.0132, -0.0114, -0.0049, 0.0006, 0.0098, 0.0039, 0.0008, -0.0051, -0.0057, -0.0012, 0.001, -0.0012, -0.0008, -0.0017, 0.002, -0.0075, 0.0056, 0.0018, -0.0075, 0.0082, 0.0021, 0.0002, -0.0032, 0.0095, -0.0003, -0.0038, 0.0003]),\n",
       " DenseVector([0.0044, 0.0017, 0.0064, 0.0012, -0.0009, -0.0023, 0.0008, -0.0001, 0.0017, 0.0004, 0.0002, 0.0, 0.004, 0.1875, 0.0552, 0.0417, 0.0708, 0.0379, 0.068, 0.0334, 0.029, 0.0249, 0.0129, 0.0289, 0.0018, -0.0059, 0.0148, 0.0123, -0.0088, -0.0079, 0.0016, 0.0042, 0.003, -0.003, 0.0041, 0.0024, -0.0276, -0.0038, -0.0127, 0.0184, -0.003, 0.0178, -0.0015, -0.0001, -0.0023, -0.0011, -0.0115, 0.0111, 0.0125, 0.0038, 0.0026, 0.0001, 0.0065, -0.004, -0.0039, 0.0118, 0.0073, -0.0079, -0.0042, -0.006, -0.004, -0.0018, 0.0011, -0.0372, 0.0039, 0.0011, -0.0081, 0.0039, 0.0042, -0.0028, 0.0042, 0.0119, 0.0013, -0.0004, 0.0016, -0.0017, -0.008, 0.0013, -0.0021, -0.0054, 0.0005, -0.0018, 0.003, 0.0039, -0.0009, -0.0029, 0.0064, 0.0011, 0.0053, 0.0025])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nor2 = Normalizer(float(\"inf\"))\n",
    "newrdd1=nor.transform(rdd)\n",
    "newrdd1.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011.0 1922.0\n"
     ]
    }
   ],
   "source": [
    "parsedDataInit = rawData.map(parsePoint)\n",
    "onlyLabels = parsedDataInit.map(lambda a: a.label)\n",
    "minYear = onlyLabels.min()\n",
    "maxYear = onlyLabels.max()\n",
    "print maxYear, minYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NewData = labeld.zip(newrdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001.0,\n",
       " DenseVector([0.0069, 0.003, 0.0101, 0.0012, -0.0024, -0.0018, -0.0035, -0.0017, 0.0011, -0.0003, 0.0005, -0.0003, 0.0014, 0.0846, 0.1316, 0.0966, 0.0566, 0.0531, 0.0452, 0.0329, 0.0348, 0.0259, 0.0139, 0.0248, -0.0012, -0.044, 0.0133, 0.0067, -0.0132, -0.0025, 0.0003, 0.0048, 0.0016, 0.0002, 0.0011, -0.0001, -0.0185, -0.0115, -0.0052, 0.0101, -0.0052, -0.0004, -0.0034, -0.0018, 0.0022, -0.0026, 0.0114, 0.0333, -0.0014, 0.0044, -0.0035, -0.0005, 0.0018, 0.0057, -0.001, -0.0029, 0.0146, 0.0089, 0.0036, -0.0062, -0.0011, 0.0011, -0.0015, -0.0132, -0.0114, -0.0049, 0.0006, 0.0098, 0.0039, 0.0008, -0.0051, -0.0057, -0.0012, 0.001, -0.0012, -0.0008, -0.0017, 0.002, -0.0075, 0.0056, 0.0018, -0.0075, 0.0082, 0.0021, 0.0002, -0.0032, 0.0095, -0.0003, -0.0038, 0.0003]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewData.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsedData = NewData.map(lambda a: LabeledPoint((1 if a[0] >=1922 else 0),a[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[18] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [.6, .2, .2]\n",
    "seed = 42\n",
    "parsedTrainData, parsedValData, parsedTestData = parsedData.randomSplit(weights,seed)\n",
    "parsedTrainData.cache()\n",
    "parsedValData.cache()\n",
    "parsedTestData.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nTrain = parsedTrainData.count()\n",
    "nVal = parsedValData.count()\n",
    "nTest = parsedTestData.count()\n",
    "\n",
    "print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
    "print parsedData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVMWithSGD.train(parsedTrainData, iterations=100,step=0.001,regParam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print model.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on training data\n",
    "labelsAndPreds = parsedTrainData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedTrainData.count())\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = BinaryClassificationMetrics(labelsAndPreds)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"train AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"train AreaUnderPrecision\" +str(APR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = BinaryClassificationMetrics(labelsAndPredsval)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"validation AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"validation AreaUnderPrecision\" +str(APR))\n",
    "\n",
    "metrics = BinaryClassificationMetrics(labelsAndPredstest)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"test AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"test AreaUnderPrecision\" +str(APR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "p = np.array(labelsAndPreds.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.array(labelsAndPredsval.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.array(labelsAndPredstest.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionWithLBFGS.train(parsedTrainData,iterations=100,regParam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.clearThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on training data\n",
    "labelsAndPreds = parsedTrainData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedTrainData.count())\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = BinaryClassificationMetrics(labelsAndPreds)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"train AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"train AreaUnderPrecision\" +str(APR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.array(labelsAndPreds.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.array(labelsAndPredsval.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.array(labelsAndPredstest.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionWithLBFGS.train(parsedTrainData,iterations=1000,regParam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.clearThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on training data\n",
    "labelsAndPreds = parsedTrainData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedTrainData.count())\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = BinaryClassificationMetrics(labelsAndPreds)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"train AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"train AreaUnderPrecision\" +str(APR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.array(labelsAndPreds.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on validation data\n",
    "labelsAndPredsval = parsedValData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "valErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedValData.count())\n",
    "print(\"validation Error = \" + str(valErr))\n",
    "\n",
    "# Evaluating the model on validation data\n",
    "labelsAndPredstest = parsedTestData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "testErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedTestData.count())\n",
    "print(\"Test Error = \" + str(testErr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.array(labelsAndPredsval.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])\n",
    "\n",
    "p = np.array(labelsAndPredstest.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GradientBoostedTrees.trainClassifier(parsedTrainData,\n",
    "    categoricalFeaturesInfo={}, numIterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on train instances and compute test error\n",
    "predictions = model.predict(parsedTrainData.map(lambda x: x.features))\n",
    "labelsAndPredictions = parsedTrainData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(parsedTrainData.count())\n",
    "print('Test Error = ' + str(testErr))\n",
    "print('Learned classification GBT model:')\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = BinaryClassificationMetrics(labelsAndPredictions)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"train AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"train AreaUnderPrecision\" +str(APR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.array(labelsAndPredictions.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on val instances and compute test error\n",
    "predictions = model.predict(parsedValData.map(lambda x: x.features))\n",
    "labelsAndPredictions = parsedValData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(parsedTrainData.count())\n",
    "print('validation Error = ' + str(testErr))\n",
    "print('Learned classification GBT model:')\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model on val instances and compute test error\n",
    "predictions = model.predict(parsedTestData.map(lambda x: x.features))\n",
    "labelsAndPredictions = parsedTestData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(parsedTestData.count())\n",
    "print('Test Error = ' + str(testErr))\n",
    "print('Learned classification GBT model:')\n",
    "print(model.toDebugString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

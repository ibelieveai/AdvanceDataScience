{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(appName='2_Income_Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPartitions = 2\n",
    "path = '/home/praneeth/Downloads/adult.data_Cfinal.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawData = sc.textFile(path, numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0,39,77516,13,2174,0,40,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0',\n",
       " u'0,50,83311,13,0,0,13,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0',\n",
       " u'0,38,215646,9,0,0,40,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0',\n",
       " u'0,53,234721,7,0,0,40,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0',\n",
       " u'0,28,338409,13,0,0,40,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0',\n",
       " u'0,37,284582,14,0,0,40,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0',\n",
       " u'0,49,160187,5,0,0,16,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0',\n",
       " u'1,52,209642,9,0,0,45,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0',\n",
       " u'1,31,45781,14,14084,0,50,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0',\n",
       " u'1,42,159449,13,5178,0,40,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors, Matrices\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "    return LabeledPoint(values[0], values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsedSamplePoints = rawData.map(parsePoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [39.0,77516.0,13.0,2174.0,0.0,40.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [50.0,83311.0,13.0,0.0,0.0,13.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [38.0,215646.0,9.0,0.0,0.0,40.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [53.0,234721.0,7.0,0.0,0.0,40.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [28.0,338409.0,13.0,0.0,0.0,40.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedSamplePoints.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[5] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [.6, .02, .02]\n",
    "seed = 42\n",
    "parsedTrainData, parsedValData, parsedTestData = parsedSamplePoints.randomSplit(weights,seed)\n",
    "parsedTrainData.cache()\n",
    "parsedValData.cache()\n",
    "parsedTestData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30561 969 1031 32561\n",
      "32561\n"
     ]
    }
   ],
   "source": [
    "nTrain = parsedTrainData.count()\n",
    "nVal = parsedValData.count()\n",
    "nTest = parsedTestData.count()\n",
    "\n",
    "print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
    "print parsedSamplePoints.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(0.0, [43.0,117037.0,7.0,0.0,2042.0,40.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedTestData.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "# Build the model\n",
    "\n",
    "model = SVMWithSGD.train(parsedTrainData, iterations=1000,step=0.001,regParam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print model.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.227806681719\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on training data\n",
    "labelsAndPreds = parsedTrainData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedTrainData.count())\n",
    "print(\"Training Error = \" + str(trainErr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 0.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsAndPreds.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train AreaUnderCurve = 0.839317004042\n"
     ]
    }
   ],
   "source": [
    "metrics = BinaryClassificationMetrics(labelsAndPreds)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"train AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"train AreaUnderPrecision\" +str(APR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Error = 7.18472652219\n",
      "Test Error = 6.75266731329\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on validation data\n",
    "labelsAndPredsval = parsedValData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "valErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedValData.count())\n",
    "print(\"validation Error = \" + str(valErr))\n",
    "\n",
    "# Evaluating the model on validation data\n",
    "labelsAndPredstest = parsedTestData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "testErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedTestData.count())\n",
    "print(\"Test Error = \" + str(testErr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation AreaUnderCurve = 0.846767466111\n",
      "test AreaUnderCurve = 0.878312070658\n"
     ]
    }
   ],
   "source": [
    "metrics = BinaryClassificationMetrics(labelsAndPredsval)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"validation AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"validation AreaUnderPrecision\" +str(APR))\n",
    "\n",
    "metrics = BinaryClassificationMetrics(labelsAndPredstest)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"test AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"test AreaUnderPrecision\" +str(APR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsAndPreds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23141,    46],\n",
       "       [ 6916,   458]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array(labelsAndPreds.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[761,   1],\n",
       "       [198,   9]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array(labelsAndPredsval.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[771,   0],\n",
       "       [248,  12]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array(labelsAndPredstest.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionWithLBFGS.train(parsedTrainData,iterations=1000,regParam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LogisticRegressionModel.clearThreshold of (weights=[0.0142509318624,2.24978144553e-07,-0.0270809882155,0.000142164465012,0.000541786462838,0.0215096224796,0.137197670849,-0.433463962045,-0.925949535162,-0.432556732088,-0.0975547652454,-0.73286058513,-0.611497342175,-2.63213036116,-1.30606537964,-1.16289252294,-0.841510571651,-1.85301856089,-1.58400619411,-1.74301528331,-1.54070546677,-0.0404973186437,-0.0458923109769,0.56806773295,1.64672987062,-0.615035058638,1.01212879401,-2.646115347,1.46732048924,-0.265668407028,-0.472679440758,1.09147927114,0.492632639275,-0.598725657021,-0.969915137113,-0.572019219608,-0.407122815891,-0.247097817598,-1.2818444637,-0.190209513874,0.481080548816,-1.03292629382,-0.837445500162,-0.524515401925,-0.947884106237,-1.39401749998,6.94826981408e-05,0.196841028393,0.0173482484742,0.293828406473,-0.347103512366,0.210734465099,-0.357141050394,-0.777840962047,-1.1201713478,-0.534785585169,1.17201184797,-1.07059709339,-0.702535325143,-0.736650738138,-1.05943300885,-0.636230904781,-0.733301593847,-0.0951943534393,0.327220333231,-0.761426333674,-1.36202446543,-2.41632820989,-0.815046051861,-2.14357713058,-1.15492939318,-1.48535341165,-0.602564714342,-0.466001892829,-0.701694333098,-1.7220381424,-1.18000806819,-1.16272448376,-1.88124778432,-1.76150607594,-1.06185984334,-1.38427192059,-1.26941262688,-0.995343213393,-0.799302509427,-0.400728570659,-1.10774160573,-0.500620468187,-1.49745132751,-1.55288133766,-1.82306040055,-2.77988236349,-1.56716538386,-0.604957376887,-1.10244938603,-1.25209264386,-1.27288980583,-1.06793655167,-1.74785767778,-1.24644458422,-1.44663777796,-1.41936700052,-0.992915941483,-1.81762384498,0.3472087904], intercept=0.0)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.clearThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.149373384379\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on training data\n",
    "labelsAndPreds = parsedTrainData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedTrainData.count())\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train AreaUnderCurve = 0.809700695293\n"
     ]
    }
   ],
   "source": [
    "metrics = BinaryClassificationMetrics(labelsAndPreds)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"train AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"train AreaUnderPrecision\" +str(APR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21714,  1473],\n",
       "       [ 3092,  4282]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array(labelsAndPreds.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Error = 4.71104231166\n",
      "Test Error = 4.4277400582\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on validation data\n",
    "labelsAndPredsval = parsedValData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "valErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedValData.count())\n",
    "print(\"validation Error = \" + str(valErr))\n",
    "\n",
    "# Evaluating the model on validation data\n",
    "labelsAndPredstest = parsedTestData.map(lambda p: (p.label, float(model.predict(p.features))))\n",
    "testErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedTestData.count())\n",
    "print(\"Test Error = \" + str(testErr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[710,  52],\n",
       "       [105, 102]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array(labelsAndPredsval.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[711,  60],\n",
       "       [111, 149]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array(labelsAndPredstest.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GradientBoostedTrees.trainClassifier(parsedTrainData,\n",
    "    categoricalFeaturesInfo={}, numIterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.162756454305\n",
      "Learned classification GBT model:\n",
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 32 <= 0.0)\n",
      "     If (feature 3 <= 7443.0)\n",
      "      If (feature 2 <= 13.0)\n",
      "       Predict: -0.9251399557349304\n",
      "      Else (feature 2 > 13.0)\n",
      "       Predict: -0.4783625730994152\n",
      "     Else (feature 3 > 7443.0)\n",
      "      If (feature 0 <= 21.0)\n",
      "       Predict: -0.6\n",
      "      Else (feature 0 > 21.0)\n",
      "       Predict: 1.0\n",
      "    Else (feature 32 > 0.0)\n",
      "     If (feature 2 <= 12.0)\n",
      "      If (feature 3 <= 7443.0)\n",
      "       Predict: -0.37475201002401587\n",
      "      Else (feature 3 > 7443.0)\n",
      "       Predict: 0.9492753623188406\n",
      "     Else (feature 2 > 12.0)\n",
      "      If (feature 3 <= 7443.0)\n",
      "       Predict: 0.3658008658008658\n",
      "      Else (feature 3 > 7443.0)\n",
      "       Predict: 0.9922330097087378\n",
      "  Tree 1:\n",
      "    If (feature 0 <= 33.0)\n",
      "     If (feature 4 <= 1844.0)\n",
      "      If (feature 3 <= 2597.0)\n",
      "       Predict: -0.5228933422820999\n",
      "      Else (feature 3 > 2597.0)\n",
      "       Predict: 0.11157087847544322\n",
      "     Else (feature 4 > 1844.0)\n",
      "      If (feature 32 <= 0.0)\n",
      "       Predict: 0.019921675961667207\n",
      "      Else (feature 32 > 0.0)\n",
      "       Predict: 1.0750878791365097\n",
      "    Else (feature 0 > 33.0)\n",
      "     If (feature 4 <= 1741.0)\n",
      "      If (feature 5 <= 41.0)\n",
      "       Predict: -0.21158085334123325\n",
      "      Else (feature 5 > 41.0)\n",
      "       Predict: 0.28690622412448363\n",
      "     Else (feature 4 > 1741.0)\n",
      "      If (feature 32 <= 0.0)\n",
      "       Predict: 0.6890108562798596\n",
      "      Else (feature 32 > 0.0)\n",
      "       Predict: 1.418496876450443\n",
      "  Tree 2:\n",
      "    If (feature 0 <= 29.0)\n",
      "     If (feature 32 <= 0.0)\n",
      "      If (feature 31 <= 0.0)\n",
      "       Predict: -0.4648816151498882\n",
      "      Else (feature 31 > 0.0)\n",
      "       Predict: 1.7261240415069148\n",
      "     Else (feature 32 > 0.0)\n",
      "      If (feature 0 <= 25.0)\n",
      "       Predict: -0.9272073419528175\n",
      "      Else (feature 0 > 25.0)\n",
      "       Predict: -0.5076158037777609\n",
      "    Else (feature 0 > 29.0)\n",
      "     If (feature 2 <= 9.0)\n",
      "      If (feature 25 <= 0.0)\n",
      "       Predict: -0.6124436234614573\n",
      "      Else (feature 25 > 0.0)\n",
      "       Predict: -0.15575472113323421\n",
      "     Else (feature 2 > 9.0)\n",
      "      If (feature 4 <= 1740.0)\n",
      "       Predict: 0.11304658235109027\n",
      "      Else (feature 4 > 1740.0)\n",
      "       Predict: 1.1064688752641534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on train instances and compute test error\n",
    "predictions = model.predict(parsedTrainData.map(lambda x: x.features))\n",
    "labelsAndPredictions = parsedTrainData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(parsedTrainData.count())\n",
    "print('Test Error = ' + str(testErr))\n",
    "print('Learned classification GBT model:')\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train AreaUnderCurve = 0.802486878864\n"
     ]
    }
   ],
   "source": [
    "metrics = BinaryClassificationMetrics(labelsAndPredictions)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"train AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"train AreaUnderPrecision\" +str(APR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22006,  1181],\n",
       "       [ 3793,  3581]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array(labelsAndPredictions.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Error = 0.00516998789307\n",
      "Learned classification GBT model:\n",
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 32 <= 0.0)\n",
      "     If (feature 3 <= 7443.0)\n",
      "      If (feature 2 <= 13.0)\n",
      "       Predict: -0.9251399557349304\n",
      "      Else (feature 2 > 13.0)\n",
      "       Predict: -0.4783625730994152\n",
      "     Else (feature 3 > 7443.0)\n",
      "      If (feature 0 <= 21.0)\n",
      "       Predict: -0.6\n",
      "      Else (feature 0 > 21.0)\n",
      "       Predict: 1.0\n",
      "    Else (feature 32 > 0.0)\n",
      "     If (feature 2 <= 12.0)\n",
      "      If (feature 3 <= 7443.0)\n",
      "       Predict: -0.37475201002401587\n",
      "      Else (feature 3 > 7443.0)\n",
      "       Predict: 0.9492753623188406\n",
      "     Else (feature 2 > 12.0)\n",
      "      If (feature 3 <= 7443.0)\n",
      "       Predict: 0.3658008658008658\n",
      "      Else (feature 3 > 7443.0)\n",
      "       Predict: 0.9922330097087378\n",
      "  Tree 1:\n",
      "    If (feature 0 <= 33.0)\n",
      "     If (feature 4 <= 1844.0)\n",
      "      If (feature 3 <= 2597.0)\n",
      "       Predict: -0.5228933422820999\n",
      "      Else (feature 3 > 2597.0)\n",
      "       Predict: 0.11157087847544322\n",
      "     Else (feature 4 > 1844.0)\n",
      "      If (feature 32 <= 0.0)\n",
      "       Predict: 0.019921675961667207\n",
      "      Else (feature 32 > 0.0)\n",
      "       Predict: 1.0750878791365097\n",
      "    Else (feature 0 > 33.0)\n",
      "     If (feature 4 <= 1741.0)\n",
      "      If (feature 5 <= 41.0)\n",
      "       Predict: -0.21158085334123325\n",
      "      Else (feature 5 > 41.0)\n",
      "       Predict: 0.28690622412448363\n",
      "     Else (feature 4 > 1741.0)\n",
      "      If (feature 32 <= 0.0)\n",
      "       Predict: 0.6890108562798596\n",
      "      Else (feature 32 > 0.0)\n",
      "       Predict: 1.418496876450443\n",
      "  Tree 2:\n",
      "    If (feature 0 <= 29.0)\n",
      "     If (feature 32 <= 0.0)\n",
      "      If (feature 31 <= 0.0)\n",
      "       Predict: -0.4648816151498882\n",
      "      Else (feature 31 > 0.0)\n",
      "       Predict: 1.7261240415069148\n",
      "     Else (feature 32 > 0.0)\n",
      "      If (feature 0 <= 25.0)\n",
      "       Predict: -0.9272073419528175\n",
      "      Else (feature 0 > 25.0)\n",
      "       Predict: -0.5076158037777609\n",
      "    Else (feature 0 > 29.0)\n",
      "     If (feature 2 <= 9.0)\n",
      "      If (feature 25 <= 0.0)\n",
      "       Predict: -0.6124436234614573\n",
      "      Else (feature 25 > 0.0)\n",
      "       Predict: -0.15575472113323421\n",
      "     Else (feature 2 > 9.0)\n",
      "      If (feature 4 <= 1740.0)\n",
      "       Predict: 0.11304658235109027\n",
      "      Else (feature 4 > 1740.0)\n",
      "       Predict: 1.1064688752641534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on val instances and compute test error\n",
    "predictions = model.predict(parsedValData.map(lambda x: x.features))\n",
    "labelsAndPredictions = parsedValData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(parsedTrainData.count())\n",
    "print('validation Error = ' + str(testErr))\n",
    "print('Learned classification GBT model:')\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.171677982541\n",
      "Learned classification GBT model:\n",
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 32 <= 0.0)\n",
      "     If (feature 3 <= 7443.0)\n",
      "      If (feature 2 <= 13.0)\n",
      "       Predict: -0.9251399557349304\n",
      "      Else (feature 2 > 13.0)\n",
      "       Predict: -0.4783625730994152\n",
      "     Else (feature 3 > 7443.0)\n",
      "      If (feature 0 <= 21.0)\n",
      "       Predict: -0.6\n",
      "      Else (feature 0 > 21.0)\n",
      "       Predict: 1.0\n",
      "    Else (feature 32 > 0.0)\n",
      "     If (feature 2 <= 12.0)\n",
      "      If (feature 3 <= 7443.0)\n",
      "       Predict: -0.37475201002401587\n",
      "      Else (feature 3 > 7443.0)\n",
      "       Predict: 0.9492753623188406\n",
      "     Else (feature 2 > 12.0)\n",
      "      If (feature 3 <= 7443.0)\n",
      "       Predict: 0.3658008658008658\n",
      "      Else (feature 3 > 7443.0)\n",
      "       Predict: 0.9922330097087378\n",
      "  Tree 1:\n",
      "    If (feature 0 <= 33.0)\n",
      "     If (feature 4 <= 1844.0)\n",
      "      If (feature 3 <= 2597.0)\n",
      "       Predict: -0.5228933422820999\n",
      "      Else (feature 3 > 2597.0)\n",
      "       Predict: 0.11157087847544322\n",
      "     Else (feature 4 > 1844.0)\n",
      "      If (feature 32 <= 0.0)\n",
      "       Predict: 0.019921675961667207\n",
      "      Else (feature 32 > 0.0)\n",
      "       Predict: 1.0750878791365097\n",
      "    Else (feature 0 > 33.0)\n",
      "     If (feature 4 <= 1741.0)\n",
      "      If (feature 5 <= 41.0)\n",
      "       Predict: -0.21158085334123325\n",
      "      Else (feature 5 > 41.0)\n",
      "       Predict: 0.28690622412448363\n",
      "     Else (feature 4 > 1741.0)\n",
      "      If (feature 32 <= 0.0)\n",
      "       Predict: 0.6890108562798596\n",
      "      Else (feature 32 > 0.0)\n",
      "       Predict: 1.418496876450443\n",
      "  Tree 2:\n",
      "    If (feature 0 <= 29.0)\n",
      "     If (feature 32 <= 0.0)\n",
      "      If (feature 31 <= 0.0)\n",
      "       Predict: -0.4648816151498882\n",
      "      Else (feature 31 > 0.0)\n",
      "       Predict: 1.7261240415069148\n",
      "     Else (feature 32 > 0.0)\n",
      "      If (feature 0 <= 25.0)\n",
      "       Predict: -0.9272073419528175\n",
      "      Else (feature 0 > 25.0)\n",
      "       Predict: -0.5076158037777609\n",
      "    Else (feature 0 > 29.0)\n",
      "     If (feature 2 <= 9.0)\n",
      "      If (feature 25 <= 0.0)\n",
      "       Predict: -0.6124436234614573\n",
      "      Else (feature 25 > 0.0)\n",
      "       Predict: -0.15575472113323421\n",
      "     Else (feature 2 > 9.0)\n",
      "      If (feature 4 <= 1740.0)\n",
      "       Predict: 0.11304658235109027\n",
      "      Else (feature 4 > 1740.0)\n",
      "       Predict: 1.1064688752641534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on val instances and compute test error\n",
    "predictions = model.predict(parsedTestData.map(lambda x: x.features))\n",
    "labelsAndPredictions = parsedTestData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(parsedTestData.count())\n",
    "print('Test Error = ' + str(testErr))\n",
    "print('Learned classification GBT model:')\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test AreaUnderCurve = 0.797235635804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[730,  41],\n",
       "       [136, 124]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = BinaryClassificationMetrics(labelsAndPredictions)\n",
    "AUC = metrics.areaUnderROC\n",
    "APR = metrics.areaUnderPR\n",
    "\n",
    "print(\"test AreaUnderCurve = \" + str(AUC))\n",
    "#print(\"train AreaUnderPrecision\" +str(APR))\n",
    "p = np.array(labelsAndPredictions.collect())\n",
    "confusion_matrix(p[:,0],p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
